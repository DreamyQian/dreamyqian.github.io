<!DOCTYPE html>
<html><head>
<title>Xuwei Qian's Homepage</title>
<link rel="icon" href="image/icon.jpg" >

<!-- <script type="text/javascript"> -->
      <!--//判断是否手机访问 如果是跳转 -->
      <!--try {-->
      <!--var urlhash = window.location.hash;-->
      <!--if (!urlhash.match("fromapp")) {-->
      <!--if ((navigator.userAgent.match(/(iPhone|iPod|Android|ios|iPad)/i))) {-->
      <!--window.location = "/mobile.html";-->
      <!--}-->
      <!--}-->
      <!--} catch (err) {}-->
<!-- </script> -->

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css">
<style type="text/css">

body
{
 	font-family: 'Lucida Grande',Arial,Helvetica,'STXihei',sans-serif; 
    background-color : #fff;
    font-size: 18px;
    width : 1440px;
}
    .content
	{
    		width : 1100px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		margin-left: 260px;
/*     		background-color : #fff;
    		box-shadow: 0px 0px 10px #999; */
/*     		border-radius: 15px;  */
	}	
	table
	{
		padding: 5px;
	}
	
  	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 990px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 1040px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		/*color: #1367a7;*/
		height: 158px;
/*     		font-size:110%; */
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h1
	{
		font-size:210%;
	}
	h2
	{
		font-size:150%;
	}
	h3
	{
		font-size:110%;
	}
	h4
	{
		font-size:100%;
	}
	p
	{
/*		color: #5B5B5B;*/
		margin-bottom: 10px;
		/*margin-left: 20px;*/
		text-indent:2em;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}

    #tsinghua_logo {
        position: absolute;
        left: 646px;
        top: 28px;
        width: 200px;
        height: 20px;
    }
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        /*-moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;*/
        /*box-shadow: 3px 3px 6px #888;*/
    }


underline {
	border-bottom: 2px solid;
	display:inline-block;
}

</style>

<script type="text/javascript" language="javascript">
	function addEventHandler(target, type, func){
	if (target.addEventListener)
	target.addEventListener(type, func, false);
	else if (target.attachEvent)
	target.attachEvent("on" + type, func);
	else target["on" + type] = func;
	}
	var advIniTop = 0;
	function move(){
	var layer1 = document.getElementById("nav1");
	if (layer1) layer1.style.top = advIniTop + document.body.scrollTop || document.documentElement.scrollTop + 10 + "px";
	}
	addEventHandler(window, "scroll", move);
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?29efd6468fd0186f0fea2a1a307a70cb";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>
</head>




<a name="home"></a>
<body>
<div id="nav1" style="position:absolute;z-index:10;top:10px;left:100px;width:200px;">
	<table>
	  <td style="height:68px">
	  </td>
	</table>
	<h2>Index</h2>
	<table>
	  <td style="height:15px">
	  </td>
	</table>
	<div style="position:absolute;z-index:10;left:2px;border-left:2px solid #3B3B3B">
	<table>
	  <td style="width:15px">
	  </td>
	  <td valign="middle">
	    <h4>
			<a href="#home" style="color: #3B3B3B">Home</a><br><br>
			<a href="#about-me" style="color: #3B3B3B">About Me</a><br><br>
			<a href="#news" style="color: #3B3B3B">News</a><br><br>
			<a href="#publications" style="color: #3B3B3B">Publications</a><br><br>
			<a href="#service" style="color: #3B3B3B">Service</a><br><br>
			<a href="#experience" style="color: #3B3B3B">Research Experience</a><br><br>
			<a href="#education" style="color: #3B3B3B">Education</a><br><br>
			<a href="#honors" style="color: #3B3B3B">Selected Honors</a><br><br>
			<a href="#misc" style="color: #3B3B3B">Misc Facts</a><br><br>
			<a href="#contact" style="color: #3B3B3B">Contact</a><br>
		</h4>
	  </td>
	</table></div><br><br>
</div>
<br>
<div class="content">
	<div id="container">
	<table>
	<tbody><tr>
<!-- 		<td style="width:65px">
  	</td> -->
	<td style="width:420px">
    <img id="myPicture" src="image/Xuwei_Qian.jpg"
	 style="float:center; border-radius: 15px"
	 height="280px">
  	</td>
	<td>
	<div id="DocInfo">
	<!--<br>-->
		<h1>Xuwei Qian (钱旭威)</h1><br>
	<h3>M.Eng. Student</h3>
	<h3>Nanjing University of Information Science & Technology</h3>
	<h3></h3>
	<font size=4.5><a href="./Xuwei_Qian_Curriculum_Vitae.pdf">CV (2022.7.29)</a> &bull; <a href="https://scholar.google.com/citations?user=WD2d8r4AAAAJ&hl=zh-CN#">Google Scholar</a> &bull; <a href="https://github.com/bigdata-qian">GitHub</a></font>
	</div>
	</td>
	</tr>
	</tbody></table>

	<a name="about-me"></a><br><br><br>
	<h2>About Me</h2><br>
	<p>
	I am a third year M.Eng. student in <a href="https://bdat.nuist.edu.cn/">B-DAT</a> of the <a href="https://auto.nuist.edu.cn/">School of Automation</a> at <a href="https://en.nuist.edu.cn/">Nanjing University of Information Science & Technology</a>, advised by Prof. <a href="https://scholar.google.com/citations?user=19dftlUAAAAJ&hl=zh-CN">Renlong Hang</a> and Prof. <a href="https://faculty.nuist.edu.cn/liuqingshan/zh_CN/index.htm">Qingshan Liu</a>. 
	Before that, I got my B.Eng. from <a href="http://english.cxxy.seu.edu.cn/">Southeast University Chengxian College</a>. </p>
	<p>
	My research interests lie in the efficient training and inference of deep learning models.
	</p>



	<a name="news"></a><br><br><br>
	<h2>News</h2><br>
	<p>
	2022.07: <a href="https://drive.google.com/file/d/1Pv2DBbFMqMSJ8UH2Xu2raPXrGES0vEE8/view?usp=sharing">Cross-Modality Contrastive Learning</a> is Accepted by TGRS (IF=8.12).
	<p>
	2022.06: Awarded by the Outstanding Graduate Dissertation 2022 & Outstanding Graduate 2022.
	<p>
	2022.04: One Project is Granted a National Invention Patent.
	<p>
	2021.12: Our <a href="https://drive.google.com/file/d/154Gxab8w8QaKW8OhEwUPDBoF7edUTbKP/view?usp=sharing">ReX</a> is Accepted by AAAI 2022.
	<p>
	2020.11: Not All Images are Worth using High Resolution! Our MSNet is Available at <a href="https://github.com/bigdata-qian/MSNet-Pytorch">Github</a>.
	<p>
<!-- 	2021.09: <a href="https://arxiv.org/pdf/2105.15075.pdf">Dynamic Vision Transformer (DVT)</a> is Accepted by NeurIPS 2021.
	<p>
	2021.09: Our <a href="https://arxiv.org/pdf/2102.04906.pdf">Survey on Dynamic Neural Networks</a> is Accepted by <font color="red">TPAMI</font> (IF=16.39).
	<p>
	2021.07: <a href="https://arxiv.org/pdf/2105.03245.pdf">AdaFocus</a> is Accepted by ICCV 2021 for <font color="red">Oral</font> Presentation.
	<p>
	2021.06: Not All Images are Worth 16x16 Words! Our Dynamic ViT (DVT) is Available at <a href="https://arxiv.org/pdf/2105.15075v1.pdf">Arxiv</a>/<a href="https://github.com/blackfeather-wang/Dynamic-Vision-Transformer">Github</a>.
	<p>
	2021.05: Selected to be an <a href="http://cvpr2021.thecvf.com/node/184">Outstanding Reviewer</a> of CVPR 2021.
	<p>
	2021.03: Three Papers are Accepted by CVPR 2021 (with one <font color="red">Oral</font>).
	<p>
	2021.01: Journal Version of <a href="https://arxiv.org/pdf/2007.10538.pdf">ISDA</a> is Accepted by <font color="red">TPAMI</font> (IF=16.39).
	<p>
	2021.01: One Paper is Accepted by ICLR 2021.
	</p> -->


    <!-- <h2>Updates</h2>
    <ul>
        <li>[2019/02/25] 3 papers are accepted by <a href="http://cvpr2019.thecvf.com/">CVPR'19</a>!</li>
        <li>[2018/10/09] I am honored with the National Scholarship of Tsinghua University.</li>
        <li>[2018/08/20] I give a talk on <a href="ICPR18_metric.pdf"> Deep Metric Learning for Pattern Recognition</a> at the <a href="http://www.icpr2018.org/index.php?m=content&c=index&a=show&catid=47&id=2">Tutorial of ICPR'18</a>.
        <li>[2018/07/26] I am honored with the Outstanding Reviewer Award of <a href="http://www.icme2018.org/">ICME'18</a>.</li>
        <li>[2018/07/17] 1 paper is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34#">TPAMI</a>!</li>
        <li>[2018/07/03] 1 paper is accepted by <a href="https://eccv2018.org/">ECCV'18</a>!</li>
        <li>[2018/05/15] I give a talk on <a href="FG18_face.pdf">Representation Learning for Face Alignment and Recognition</a> at the <a href="https://fg2018.cse.sc.edu/tutorial.html">Tutorial of FG'18</a>.
        <li>[2018/02/28] 2 papers are accepted by <a href="http://cvpr2018.thecvf.com/">CVPR'18</a>!</li>
        <li>[2017/10/10] I am honored with the National Scholarship of Tsinghua University.</li>
        <li>[2017/05/25] 1 paper is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34#">TPAMI</a>!</li>
        <li>[2017/03/03] 1 paper is accepted by <a href="http://cvpr2017.thecvf.com/">CVPR'17</a>!</li>
        <li>[2017/02/27] 1 paper is accepted by <a href="http://www.icme2017.org/">ICME'17</a>!</li>
        </ul> -->


  <a name="publications"></a><br><br><br>
  <h2>Recent Publications & Preprints</h2><br>


	<table>
	  <td style="width:230px; height:110px" valign="middle" align='middle'>
	    <img src="image/rex.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>ReX: An Efficient Approach to Reducing Memory Cost in Image Classification</b><br>
			<i>Association for the Advancement of Artificial Intelligence (<b>AAAI</b>, CCF-A) 2022</i><br>
	    	<b>Xuwei Qian</b>, Renlong Hang, and Qinshan Liu<br>
	    	[<a href="https://drive.google.com/file/d/154Gxab8w8QaKW8OhEwUPDBoF7edUTbKP/view?usp=sharing">PDF</a>] [Code (to be added)] [<a href="https://drive.google.com/file/d/17J8AoXNojhjdYcExBuxO1wLkTBE3A1qD/view?usp=sharing">Poster</a>] <br>
			We propose a novel approach named recurrent aggregation operator (ReX), which uses recurrent neural networks (RNNs) to effectively aggregate intra-patch features within a large receptive field, while bypassing large early activations.
		</div>
	</tr></tbody>
	</table><br><br>


	<table>
	  <tbody><tr>
	  <td style="width:230px; height:110px" valign="middle" align='middle'>
	    <img src="image/cms.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>Cross-Modality Contrastive Learning for Hyperspectral Image Classification</b><br>
			<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>, Q1, IF=8.12), 2022</i><br>
	    	Renlong Hang, <b>Xuwei Qian</b>, and Qinshan Liu<br>
	    	[<a href="https://drive.google.com/file/d/1Pv2DBbFMqMSJ8UH2Xu2raPXrGES0vEE8/view?usp=sharing">PDF</a>]<br>
			We first propose an unsupervised feature learning model using multimodel data, hyperspectral, and light detection and ranging (LiDAR) in particular. After that, we design a dual fine-tuning strategy to transfer the extracted features for hyperspectral image classification with small numbers of training samples.
	    </div>
	</tr></tbody>
	</table><br><br>


	<table>
	  <td style="width:230px; height:110px" valign="middle" align='middle'>
	    <img src="image/msnet.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>Multi-resolution Synergistic Networks for Adaptive Inference</b><br>
			<i>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>, Q1, IF=5.86) 2022</i><br>
	    	Renlong Hang, <b>Xuwei Qian</b>, and Qinshan Liu<br>
	    	[PDF (to be added)] [<a href="https://github.com/bigdata-qian/MSNet-Pytorch">Code</a>]<br>
			We develop a multi-resolution synergistic network (MSNet) to automatically configure its own optimal exit for each individual image, leading to a significant improvement in computational efficiency, both theoretically and empirically.
		</div>
	</tr></tbody>
	</table><br><br>



	<table>
		<td style="width:20px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>Currently, I have several papers under review as well. I hope I will receive positive results. If you are interested in my research, please feel free to reach me.</b><br>

		</div>
	</tr></tbody>
	</table>


	<a name="service"></a><br><br><br>
  <h2>Academic Service</h2><br>
	  <table>
	  <tbody><tr>
	  <td style="width:20px">
	  </td>
	  <td style="width:30px">
	  </td>
	  <td valign="middle">
	    <div>
	    Reviewer for TIP, TNNLS, TGRS, TCSVT, ...<br>
			<br>
		Reviewer for NeurIPS, ICLR, CVPR, AAAI, ...<br>
	    </ul>
	    </div>
	  </td>
	  </tr></tbody>
	  </table>

	<a name="experience"></a><br><br><br>
  	<h2>Research Experience</h2><br>
	  <table>
	  <tbody><tr>
	  <td style="width:20px">
	  </td>
	  <td style="width:30px">
	  </td>
	  <td valign="middle">
	    <div>
	    <b>B-DAT, Nanjing University of Information Science & Technology, China.</b><br>
	    2019.10 - Present
	    </ul>
	    </div>
	  </td>
	  </tr></tbody>
	  </table><br>
	  <table>
	  <tbody><tr>
	  <td style="width:20px">
	  </td>
	  <td style="width:30px">
	  </td>
	  <td valign="middle">
	    <div>
	    <b>Intern, <a href="https://df.nuist.edu.cn/main.htm">Engineering Research Center of Digital Forensics Ministry of Education</a>, Nanjing, China.</b><br>
		2020.6 - 2021.6, advised by Prof. <a href="https://faculty.nuist.edu.cn/zhangkaihua/zh_CN/index.htm">Kaihua Zhang</a>.
	    </ul>
	    </div>
	  </td>
	  </tr></tbody>
	  </table>


	<a name="education"></a><br><br><br>
  <h2>Education</h2><br>
	  <table>
	  <tbody><tr>
	  <td style="width:20px">
	  </td>
	  <td style="width:110px; height:110px" valign="middle">
	    <img src="image/nuist.jpg" height="100px">
	  </td>
	  <td style="width:30px">
	  </td>
	  <td valign="middle">
	    <div>
	    <b>M.Eng. in Pattern Recognition and Machine Learning, Nanjing University of Information Science & Technology, China.</b><br>
	    2019.8 - Present
	    </ul>
	    </div>
	  </td>
	  </tr></tbody>
	  </table><br>

	  <table>
	  <tbody><tr>
	  <td style="width:20px">
	  </td>
	  <td style="width:110px; height:110px" valign="middle">
	    <img src="image/seu.jpg" height="100px">
	  </td>
	  <td style="width:30px">
	  </td>
	  <td valign="middle">
	    <div>
	    <b>B.Eng. in Electric Automation, Southeast University Chengxian College, China.</b><br>
		2014.8 - 2018.6
	    </ul>
	    </div>
	  </td>
	  </tr></tbody>
	  </table>


    <a name="honors"></a><br><br><br>
    <h2>Selected Honors</h2><br>
        <ul>
            <li>Outstanding Graduate of Nanjing University of Information Science & Technology, 2022 </li>
            <li>Merit Student of Nanjing University of Information Science & Technology, 2022 </li>
            <li>Scholarship for Outstanding Academic Performance, NUIST, 2019-2022 (<b>Top 5%</b>)</li>
            <li>First Prize in The 8th Undergraduate Mathematical Contest in Modeling, 2017 (<b>Top 0.2%</b>)</li>
            <li>Outstanding Graduate of Southeast University Chengxian College, 2018 </li>
         </ul>

<!--     <h2>Professional Activities</h2>
        <ul>
            <li><b>Reviewer</b>, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018-.</li>
            <li><b>Reviewer</b>, IEEE Transactions on Image Processing, 2017-.</li>
            <li><b>Reviewer</b>, IEEE Transactions on Circuits and Systems for Video Technology, 2017-.</li>
            <li><b>Reviewer</b>, IEEE Transactions on Information Forensics and Security, 2018-.</li>
            <li><b>Reviewer</b>, IEEE Transactions on Biometrics, Behavior, and Identity Science, 2018-.</li>
            <li><b>Reviewer</b>, IEEE Access, 2018-.</li>
            <li><b>Reviewer</b>, Pattern Recognition, 2016-.</li>
            <li><b>Reviewer</b>, Journal of Visual Communication and Image Representation, 2017-.</li>
            <li><b>Reviewer</b>, International Journal of Machine Learning and Cybernetics, 2018-.</li>
            <li><b>Reviewer</b>, Multimedia Systems, 2018-.</li>
            <li><b>Reviewer</b>, IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019.</li>
            <li><b>Reviewer</b>, IEEE International Conference on Computer Vision, 2019.</li>
            <li><b>Reviewer</b>, IEEE International Conference on Multimedia and Expo, 2018.</li>
            <li><b>Reviewer</b>, IEEE International Conference on Image Processing, 2017-2018.</li>
        </ul>   -->


	<a name="misc"></a><br><br><br>
	<h2>Miscellaneous Facts</h2><br>
		<p>Now I mainly focus on my research and work hard to publish more papers.</p>


	<a name="contact"></a><br><br><br>
	<h2>Contact</h2><br>
	<table>
    <tbody><tr>
    <td style="width:15px">
    </td>
    <td valign="middle">
      <div>
      Email: 20191223049@nuist.edu.cn<p></p>
      Address: Room N305, Academic Building No.3, NUIST, Nanjing
      </div>
    </td>
    </tr></tbody>
    </table>

</div>
</div>
<!--<br>-->

<center>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=500&t=tt&d=Skb__L3rRQTUS6LP2xGVpILlpIBy2ZE_lTYFxPjZvA0'></script>
</center>

<br>
<br>
<br>
<center><font size=3 style="color: #3B3B3B">—&nbsp;&nbsp; Last updated: Jul, 2022 &nbsp;&nbsp;—</font></center><br>
<!-- <center><font size=2 style="color: #BBBBBB">Source code from <a href="https://www.antao.site/">here</a>.</font></center><br> -->
</body></html>
